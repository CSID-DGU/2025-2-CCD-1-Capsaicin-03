import sounddevice as sd
import numpy as np
import whisper
import queue
import tempfile
import os
import wave

# ===== Whisper ëª¨ë¸ ë¡œë“œ =====
model = whisper.load_model("medium")  # ì†ë„ì™€ ì •í™•ë„ ê· í˜•

# ===== ìŒì„± ë…¹ìŒ ì„¤ì • =====
SAMPLE_RATE = 16000  # Whisper ê¶Œì¥ ìƒ˜í”Œë§
CHANNELS = 1
RECORD_SECONDS = 15   # í•œ ë²ˆì— ë…¹ìŒí•  ê¸¸ì´

audio_queue = queue.Queue()

# ===== ë§ˆì´í¬ ì…ë ¥ ì½œë°± =====
def audio_callback(indata, frames, time, status):
    if status:
        print(f"[ë§ˆì´í¬ ì˜¤ë¥˜] {status}")
    audio_queue.put(indata.copy())
    
    # ===== ë…¹ìŒ í›„ Whisper ì²˜ë¦¬ í•¨ìˆ˜ =====
def get_child_speech():
    print("ğŸ¤ ë§ˆì´í¬ì—ì„œ ìŒì„±ì„ ë“£ê³  ìˆìŠµë‹ˆë‹¤... 5ì´ˆê°„ ë§í•´ë³´ì„¸ìš”.")
    frames = []

    with sd.InputStream(
        samplerate=SAMPLE_RATE,
        channels=CHANNELS,
        callback=audio_callback
    ):
        for _ in range(int(SAMPLE_RATE / 1024 * RECORD_SECONDS)):
            frames.append(audio_queue.get())

    # numpy ë°°ì—´ë¡œ ë³€í™˜
    audio_data = np.concatenate(frames, axis=0)

    # ì„ì‹œ WAV íŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmpfile:
        wav_path = tmpfile.name
        with wave.open(wav_path, 'w') as wf:
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(2)  # 16bit
            wf.setframerate(SAMPLE_RATE)
            wf.writeframes((audio_data * 32767).astype(np.int16).tobytes())

    # Whisperë¡œ STT
    result = model.transcribe(wav_path, language="ko")
    os.remove(wav_path)
    text = result.get("text", "").strip()
    return text

# ===== í…ŒìŠ¤íŠ¸ =====
if __name__ == "__main__":
    transcript = transcribe_live()
    print("ğŸ“ ì¸ì‹ ê²°ê³¼:", transcript)
